{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbKVfq/+ZpedTn9/8pz/Ba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srini-c28/GEN-AI---lab-work/blob/main/0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S5blEOgbHnVC",
        "outputId": "b9783e79-afdf-492c-c834-6a627f47b4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7e34535cef518fd0db.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7e34535cef518fd0db.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "def train_and_predict(data):\n",
        "    \"\"\"Trains a linear regression model and makes predictions.\"\"\"\n",
        "    try:\n",
        "        lines = data.splitlines()\n",
        "        data_points = []\n",
        "        for line in lines:\n",
        "            try:\n",
        "                x, y = map(float, line.split(','))\n",
        "                data_points.append([x, y])\n",
        "            except ValueError:\n",
        "                return \"Invalid input format. Please use 'x,y' per line.\"\n",
        "\n",
        "        if not data_points:\n",
        "            return \"Please provide data points.\"\n",
        "\n",
        "        data_points = np.array(data_points)\n",
        "        X = data_points[:, 0].reshape(-1, 1)\n",
        "        y = data_points[:, 1]\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(X, y, label='Data Points')\n",
        "        plt.plot(X_test, y_pred, color='red', label='Linear Regression')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.title('Linear Regression Model')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot to buffer\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "        plt.close() # Close the figure to prevent display in notebook\n",
        "        image_html = f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Linear Regression Plot\">'\n",
        "\n",
        "        #Generate prediction string\n",
        "        prediction_string = \"Predictions:\\n\"\n",
        "        for i in range(len(X_test)):\n",
        "            prediction_string += f\"X: {X_test[i][0]:.2f}, Predicted Y: {y_pred[i]:.2f}\\n\"\n",
        "\n",
        "        return image_html + \"<br><br>\" + prediction_string\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=train_and_predict,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Enter your data points (x,y) separated by commas, one pair per line.\"),\n",
        "    outputs=gr.HTML(),\n",
        "    title=\"Linear Regression Model\",\n",
        "    description=\"Enter data points in the format 'x,y' (e.g., '1,2', '2,4', '3,5'). The model will train and display the regression line and predictions.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "def predict_cricket_score(data):\n",
        "    \"\"\"Trains a linear regression model and predicts cricket scores.\"\"\"\n",
        "    try:\n",
        "        lines = data.splitlines()\n",
        "        data_points = []\n",
        "        for line in lines:\n",
        "            try:\n",
        "                overs, score = map(float, line.split(','))\n",
        "                data_points.append([overs, score])\n",
        "            except ValueError:\n",
        "                return \"Invalid input format. Please use 'overs,score' per line.\"\n",
        "\n",
        "        if not data_points:\n",
        "            return \"Please provide data points (overs and score).\"\n",
        "\n",
        "        data_points = np.array(data_points)\n",
        "        X = data_points[:, 0].reshape(-1, 1)  # Overs\n",
        "        y = data_points[:, 1]  # Score\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(X, y, label='Actual Scores')\n",
        "        plt.plot(X_test, y_pred, color='red', label='Predicted Scores')\n",
        "        plt.xlabel('Overs')\n",
        "        plt.ylabel('Score')\n",
        "        plt.title('Cricket Score Prediction')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot to buffer\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "        plt.close() # Close the figure\n",
        "\n",
        "        image_html = f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Cricket Score Prediction Plot\">'\n",
        "\n",
        "        #Generate prediction string\n",
        "        prediction_string = \"Predictions:\\n\"\n",
        "        for i in range(len(X_test)):\n",
        "            prediction_string += f\"Overs: {X_test[i][0]:.2f}, Predicted Score: {y_pred[i]:.2f}\\n\"\n",
        "\n",
        "        return image_html + \"<br><br>\" + prediction_string\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_cricket_score,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Enter overs and score (overs,score) separated by commas, one pair per line.\"),\n",
        "    outputs=gr.HTML(),\n",
        "    title=\"Cricket Score Prediction\",\n",
        "    description=\"Enter overs and corresponding scores in the format 'overs,score' (e.g., '10,50', '20,100', '30,150'). The model will predict scores based on overs.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "DhJ35ftDLxFW",
        "outputId": "be3ff609-b1a7-491d-a313-2246ed61919b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6dd3e4ab9b9fc2f37e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6dd3e4ab9b9fc2f37e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "def predict_cricket_outcome(data):\n",
        "    \"\"\"Trains a logistic regression model and predicts cricket outcome (win/loss).\"\"\"\n",
        "    try:\n",
        "        lines = data.splitlines()\n",
        "        data_points = []\n",
        "        for line in lines:\n",
        "            try:\n",
        "                overs, runs_required, outcome = line.split(',')\n",
        "                overs = float(overs)\n",
        "                runs_required = float(runs_required)\n",
        "                outcome = int(outcome)  # 1 for win, 0 for loss\n",
        "                data_points.append([overs, runs_required, outcome])\n",
        "            except ValueError:\n",
        "                return \"Invalid input format. Please use 'overs,runs_required,outcome(1/0)' per line.\"\n",
        "\n",
        "        if not data_points:\n",
        "            return \"Please provide data points (overs, runs_required, outcome).\"\n",
        "\n",
        "        data_points = np.array(data_points)\n",
        "        X = data_points[:, :2]  # Overs and runs_required\n",
        "        y = data_points[:, 2]  # Outcome (1 or 0)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Plotting (Simplified for 2D classification)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        for i in range(len(X)):\n",
        "            if y[i] == 1:\n",
        "                plt.scatter(X[i, 0], X[i, 1], color='green', label='Win' if i == 0 else \"\")\n",
        "            else:\n",
        "                plt.scatter(X[i, 0], X[i, 1], color='red', label='Loss' if i == 0 else \"\")\n",
        "\n",
        "        plt.xlabel('Overs')\n",
        "        plt.ylabel('Runs Required')\n",
        "        plt.title('Cricket Outcome Prediction (Win/Loss)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot to buffer\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "        plt.close()\n",
        "\n",
        "        image_html = f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Cricket Outcome Prediction Plot\">'\n",
        "\n",
        "        # Generate prediction string\n",
        "        prediction_string = \"Predictions:\\n\"\n",
        "        for i in range(len(X_test)):\n",
        "            prediction_string += f\"Overs: {X_test[i][0]:.2f}, Runs Required: {X_test[i][1]:.2f}, Predicted Outcome: {'Win' if y_pred[i] == 1 else 'Loss'}\\n\"\n",
        "\n",
        "        return image_html + \"<br><br>\" + prediction_string\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_cricket_outcome,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Enter overs, runs_required, outcome (1/0) separated by commas, one triplet per line.\"),\n",
        "    outputs=gr.HTML(),\n",
        "    title=\"Cricket Outcome Prediction (Logistic Regression)\",\n",
        "    description=\"Enter overs, runs required, and outcome (1 for win, 0 for loss) in the format 'overs,runs_required,outcome' (e.g., '10,50,1', '20,100,0'). The model will predict win/loss based on overs and runs required.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "_P0fnSHaNxqr",
        "outputId": "c668a002-3fa4-4c35-edde-95f91690d9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e1d174c801bf649d68.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e1d174c801bf649d68.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def flames_compatibility(name1, name2):\n",
        "    \"\"\"Calculates love compatibility using the FLAMES method.\"\"\"\n",
        "    try:\n",
        "        if not name1 or not name2:\n",
        "            return \"Please enter both names.\"\n",
        "\n",
        "        name1 = re.sub(r'[^a-zA-Z]', '', name1).lower()\n",
        "        name2 = re.sub(r'[^a-zA-Z]', '', name2).lower()\n",
        "\n",
        "        common_chars = \"\"\n",
        "        for char in name1:\n",
        "            if char in name2:\n",
        "                common_chars += char\n",
        "                name2 = name2.replace(char, '', 1)\n",
        "\n",
        "        name1_unique = \"\".join(c for c in name1 if c not in common_chars)\n",
        "        name2_unique = \"\".join(c for c in name2 if c not in common_chars)\n",
        "\n",
        "        total_unique_chars = len(name1_unique) + len(name2_unique)\n",
        "\n",
        "        flames = \"FLAMES\"\n",
        "        while len(flames) > 1:\n",
        "            index = (total_unique_chars % len(flames)) - 1\n",
        "            if index == -1:\n",
        "                index = len(flames) - 1\n",
        "            flames = flames[:index] + flames[index + 1:]\n",
        "\n",
        "        result = {\n",
        "            \"F\": \"Friends\",\n",
        "            \"L\": \"Lovers\",\n",
        "            \"A\": \"Affection\",\n",
        "            \"M\": \"Marriage\",\n",
        "            \"E\": \"Enemies\",\n",
        "            \"S\": \"Soulmates\",\n",
        "        }[flames]\n",
        "\n",
        "        return f\"FLAMES Result: {result}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=flames_compatibility,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Name 1\"),\n",
        "        gr.Textbox(label=\"Name 2\"),\n",
        "    ],\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"FLAMES Love Compatibility\",\n",
        "    description=\"Enter two names to calculate love compatibility using the FLAMES method.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "i5g_2nxQO6yc",
        "outputId": "5f3a1ea7-50f7-465c-f40e-2140b6a32063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f30b97671ae3421ee1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f30b97671ae3421ee1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekaIA0ghS4ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykpDJG4IQrAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}